name: FREE Sign Lead Scraper (96-Hour Cycle)

on:
  # Run every 96 hours (4 days) - GitHub Actions uses UTC
  # This runs at midnight UTC every 4 days
  schedule:
    - cron: '0 0 */4 * *'
  
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      single_state:
        description: 'Optional: Scrape single state (e.g., Texas)'
        required: false
        type: string

jobs:
  scrape-leads:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours max
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm install
      
      - name: Run FREE lead scraper (Google only)
        env:
          # Multiple Google API keys (comma-separated) - 100% FREE
          GOOGLE_API_KEYS: ${{ secrets.GOOGLE_API_KEYS }}
          GOOGLE_SEARCH_ENGINE_IDS: ${{ secrets.GOOGLE_SEARCH_ENGINE_IDS }}
          
          # Fallback to single key for backward compatibility
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          GOOGLE_SEARCH_ENGINE_ID: ${{ secrets.GOOGLE_SEARCH_ENGINE_ID }}
          
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPO: ${{ github.repository }}
          OUTPUT_DIR: ./state-pages
          SINGLE_STATE: ${{ github.event.inputs.single_state }}
        run: node scraper-backend.js
      
      - name: Generate API usage report
        run: |
          if [ -f state-pages/scrape-summary.json ]; then
            echo "ðŸ“Š API Key Usage Report" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
            jq '.apiKeyUsage' state-pages/scrape-summary.json >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Check for changes
        id: git-check
        run: |
          git diff --exit-code state-pages/ || echo "changes=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push updated state pages
        if: steps.git-check.outputs.changes == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Bot"
          git add state-pages/
          git add next-run.json
          git commit -m "ðŸ¤– Enhanced scrape: $(jq -r '.totalLeads' state-pages/scrape-summary.json) quality leads | Next run: $(jq -r '.nextRun' state-pages/scrape-summary.json)"
          git push
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: scrape-results-${{ github.run_number }}
          path: |
            state-pages/scrape-summary.json
            state-pages/raw-data/
          retention-days: 90
      
      - name: Post success summary
        if: success()
        run: |
          echo "âœ… FREE lead scraping completed!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“ˆ Results (100% Free - No Paid Services)" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Leads:** $(jq -r '.totalLeads' state-pages/scrape-summary.json)" >> $GITHUB_STEP_SUMMARY
          echo "- **States Processed:** $(jq -r '.statesProcessed' state-pages/scrape-summary.json)" >> $GITHUB_STEP_SUMMARY
          echo "- **Duration:** $(jq -r '.durationSeconds' state-pages/scrape-summary.json)s" >> $GITHUB_STEP_SUMMARY
          echo "- **Next Run:** $(jq -r '.nextRun' state-pages/scrape-summary.json)" >> $GITHUB_STEP_SUMMARY
          echo "- **Monthly Cost:** $0.00 (100% Free)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ† Top 10 States by Lead Count" >> $GITHUB_STEP_SUMMARY
          jq -r '.stateBreakdown | sort_by(-.leadCount) | .[:10] | .[] | "- **\(.state):** \(.leadCount) leads"' state-pages/scrape-summary.json >> $GITHUB_STEP_SUMMARY
      
      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸš¨ Enhanced Scraper Failed',
              body: `The enhanced lead scraper failed to complete.
              
              **Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
              **Time:** ${new Date().toISOString()}
              **Scheduled Interval:** Every 96 hours
              
              Please check the workflow logs for details.`,
              labels: ['automation', 'bug', 'high-priority']
            })
